### Wikipedia parsing for Huawei

(As they didn't need this, I think I have the right to publish it)

What this does:

These are scripts for preparing a dataset of normalised entities from Wikipedia. This dataset is supposed to contain several types of NEs (PER, ORG, LOC for example) with connection to their aliases drawn from Wikipedia. Aliases include morphological, orthographical variants, acronyms etc. 

This work is unfinished, so some things are quite experimental. What has been done: retrieving redirects and backlinks from Wiki dumps. 

I don't expect someone to use them, but feel free to, anyway.